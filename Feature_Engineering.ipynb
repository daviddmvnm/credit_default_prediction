{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Objectives of this Notebook\n",
    "In this notebook, I will download reduced DataFrames that consist of the columns deemed most important by a simple decision tree model, along with aggregated features of the columns considered least informative by the model. The goals of this feature engineering process are as follows:\n",
    "\n",
    "1. **Feature Engineering**: I will perform further feature engineering to model various factors that, based on domain knowledge and insights from the Exploratory Data Analysis (EDA), are key predictors of default risk, I will then use RFE o slect an optimal feature set\n",
    "\n",
    "2. **Pipeline Creation**: A pipeline will be created to generate these features from a reduced dataset with matching columns. This pipeline will be utilized on the `application_test_reduced` dataset and can be hypothetically applied to new incoming data.\n",
    "\n",
    "\n",
    "\n",
    "## Feature Engineering Process\n",
    "\n",
    "1. **Iniital Hypotheses**: I will formulate hypotheses based on insights from EDA as to what features could improve predictive power\n",
    "\n",
    "2. **Automate transformations**: I will utilise tools like sklearn pipelines to handle transformations sequentially, with modular steps for scaling and feature creation. This is vital for point 3...\n",
    "\n",
    "3. **Batch test created features**: I will be creating and evaluating features in batches to manage complexity and track any impact of created features and transformations, these features will be grouped by hypothesis, these features will be evaluated against simple baseline models.\n",
    "\n",
    "4. **Assessing Robustness**: The robustness of selected features will be tested across a variety of different models and data splits and feature sets, cross validation wll used to assess the models ability to generalise.\n",
    "\n",
    "5. **Final Selection**: Confirm a final high-quality feature set. Finalise the selection with techniques like RFE and SHAP\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation Strategy\n",
    "When comparing model performance, I will follow this strategy:\n",
    "\n",
    "1. **Initial Training and Testing**: Initially, I will train and test models using the `application_train` dataset for convenience. This approach will allow for iterative refinement, hyperparameter tuning, and analysis of feature importance.\n",
    "\n",
    "2. **Final Model Training**: Once satisfactory performance is achieved on the training set, I will retrain the model using the entire `application_train` dataset to leverage all available data for enhanced performance.\n",
    "\n",
    "3. **Preprocessing and Feature Engineering on Application Test**: I will apply the same preprocessing and feature engineering pipelines to the `application_test` dataset to ensure consistency in feature representation.\n",
    "\n",
    "4. **Scoring Metrics**: After applying the trained model to the `application_test` set, I will calculate scoring metrics (such as accuracy, precision, recall, F1-score, AUC, etc.) to evaluate how well the model generalizes to unseen data.\n",
    "\n",
    "This structured approach will help ensure a thorough and systematic feature engineering process, leading to robust model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna('Unknown', inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:132: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:53: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna('Unknown', inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:116: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:132: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].mode()[0], inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:587: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:587: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:587: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\pipelines.py:587: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(X[col].median(), inplace=True)\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_20664\\164582286.py:46: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n"
     ]
    }
   ],
   "source": [
    "#importing and reducing dfs\n",
    "import pandas as pd\n",
    "ap_df = pd.read_csv(\"application_train_train.csv\")\n",
    "cr_df = pd.read_csv(\"credit_card_balance.csv\")\n",
    "ap_val_df = pd.read_csv(\"application_train_val.csv\")\n",
    "\n",
    "from pipelines import application_cleaning_pipeline, application_encoding_pipeline, application_reduction_pipeline\n",
    "from pipelines import credit_aggregation_pipeline, credit_cleaning_pipeline, credit_encoding_pipeline, credit_reduction_pipeline\n",
    "\n",
    "\n",
    "### train set for hypotheses\n",
    "\n",
    "ap_df = application_cleaning_pipeline.fit_transform(ap_df)\n",
    "ap_df = application_encoding_pipeline.fit_transform(ap_df)\n",
    "ap_df = pd.concat([application_reduction_pipeline.named_steps['top_feature_selector'].transform(ap_df),\n",
    "                        application_reduction_pipeline.named_steps['aggregator'].transform(ap_df)], axis=1)\n",
    "\n",
    "\n",
    "### validation set for hypotheses\n",
    "\n",
    "\n",
    "ap_val_df = application_cleaning_pipeline.fit_transform(ap_val_df)\n",
    "ap_val_df = application_encoding_pipeline.fit_transform(ap_val_df)\n",
    "ap_val_df = pd.concat([application_reduction_pipeline.named_steps['top_feature_selector'].transform(ap_val_df),\n",
    "                       application_reduction_pipeline.named_steps['aggregator'].transform(ap_val_df)], axis=1)\n",
    "\n",
    "\n",
    "### additional information from credit set\n",
    "\n",
    "cr_df = credit_aggregation_pipeline.fit_transform(cr_df)\n",
    "cr_df = credit_cleaning_pipeline.fit_transform(cr_df)\n",
    "cr_df = credit_encoding_pipeline.fit_transform(cr_df)\n",
    "cr_df = pd.concat([\n",
    "    credit_reduction_pipeline.named_steps['feature_selector'].transform(cr_df),\n",
    "    credit_reduction_pipeline.named_steps['payment_behavior_aggregator'].transform(cr_df) \n",
    "], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "### function to merge application data with credit data in chunks\n",
    "def merge_application_with_credit(application_df, credit_df, chunk_size=10000):\n",
    "    merged_result = pd.DataFrame()\n",
    "    for i in range(0, len(application_df), chunk_size):\n",
    "        # Process each chunk and merge with credit data\n",
    "        chunk = application_df.iloc[i:i+chunk_size]\n",
    "        merged_chunk = pd.merge(chunk, credit_df, on='SK_ID_CURR', how='inner')\n",
    "        merged_result = pd.concat([merged_result, merged_chunk], ignore_index=True)\n",
    "    return merged_result\n",
    "\n",
    "#Merge both application train and validation data with credit data\n",
    "merged_train_df = merge_application_with_credit(ap_df, cr_df)\n",
    "merged_val_df = merge_application_with_credit(ap_val_df, cr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "SK_ID_CURR\n",
      "EXT_SOURCE_2\n",
      "EXT_SOURCE_3\n",
      "DAYS_BIRTH\n",
      "DAYS_ID_PUBLISH\n",
      "DAYS_REGISTRATION\n",
      "AMT_ANNUITY\n",
      "DAYS_EMPLOYED\n",
      "DAYS_LAST_PHONE_CHANGE\n",
      "AMT_CREDIT\n",
      "REGION_POPULATION_RELATIVE\n",
      "AMT_INCOME_TOTAL\n",
      "AMT_GOODS_PRICE\n",
      "EXT_SOURCE_1\n",
      "HOUR_APPR_PROCESS_START\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "OWN_CAR_AGE\n",
      "LIVINGAREA_AVG\n",
      "YEARS_BEGINEXPLUATATION_AVG\n",
      "OBS_30_CNT_SOCIAL_CIRCLE\n",
      "APARTMENTS_AVG\n",
      "OBS_60_CNT_SOCIAL_CIRCLE\n",
      "CNT_FAM_MEMBERS\n",
      "COMMONAREA_AVG\n",
      "YEARS_BUILD_AVG\n",
      "NAME_EDUCATION_TYPE\n",
      "NONLIVINGAREA_AVG\n",
      "LANDAREA_AVG\n",
      "BASEMENTAREA_AVG\n",
      "LIVINGAPARTMENTS_AVG\n",
      "CNT_CHILDREN\n",
      "NAME_FAMILY_STATUS_Married\n",
      "CODE_GENDER\n",
      "FLAG_OWN_REALTY\n",
      "TOTAL_DOCUMENT_FLAGS\n",
      "STABILITY_INDEX\n",
      "CONTACT_INDEX\n",
      "CREDIT_BUREAU_REQ_TOTAL\n",
      "SOCIAL_CIRCLE_OBS_TOTAL\n",
      "SOCIAL_CIRCLE_DEF_TOTAL\n",
      "AMT_PAYMENT_CURRENT_mean\n",
      "AMT_DRAWINGS_OTHER_CURRENT_sum\n",
      "CNT_DRAWINGS_ATM_CURRENT_sum\n",
      "AMT_TOTAL_RECEIVABLE_mean\n",
      "AMT_BALANCE_mean\n",
      "AMT_CREDIT_LIMIT_ACTUAL_mean\n",
      "SK_ID_PREV_count\n",
      "AMT_INST_MIN_REGULARITY_mean\n",
      "AMT_RECIVABLE_mean\n",
      "AMT_RECEIVABLE_PRINCIPAL_mean\n",
      "AMT_RECIVABLE_sum\n",
      "AMT_RECEIVABLE_PRINCIPAL_sum\n",
      "CNT_INSTALMENT_MATURE_CUM_sum\n",
      "MONTHS_BALANCE_max\n",
      "SK_DPD_max\n",
      "SK_DPD_DEF_max\n",
      "Payment_Behavior_Index\n"
     ]
    }
   ],
   "source": [
    "for col in merged_train_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses from EDA\n",
    "### 1. Hypothesis on Skewness and Feature Transformation\n",
    "\n",
    "**Hypothesis**: *Right-skewed financial features may reduce model stability and predictive accuracy. Applying log transformations to these skewed variables will improve distribution normality, enabling models to better capture relationships.*\n",
    "\n",
    "**Rationale**:\n",
    "- Financial metrics like income, credit balance, and receivables show heavy right-skew due to high-value outliers.\n",
    "- Skewness can reduce performance in models that assume or benefit from Gaussian-like distributions (e.g., linear models, some tree-based algorithms), potentially introducing bias and reducing interpretability.\n",
    "\n",
    "**Approach**:\n",
    "- Apply log transformations to skewed financial features and analyze the resulting distributions.\n",
    "- Assess model performance on both transformed and untransformed data, measuring predictive accuracy and stability across validation sets.\n",
    "\n",
    "----\n",
    "\n",
    "### 2. Hypothesis on Non-linear Relationship between Income and Default Rates\n",
    "\n",
    "**Hypothesis**: *Income does not have a linear relationship with default probability; rather, higher incomes only start correlating with reduced default rates beyond the 75th percentile. Using polynomial features will help capture this non-linear relationship.*\n",
    "\n",
    "**Rationale**:\n",
    "- EDA revealed that income levels up to the 75th percentile show a relatively uniform default rate, suggesting that default likelihood remains high for lower income levels.\n",
    "- Income only begins to meaningfully predict reduced default rates for values above this threshold, indicating a non-linear relationship.\n",
    "- Introducing polynomial terms for income could allow the model to account for this non-linear effect, making it sensitive to higher incomes while maintaining accuracy for lower ranges.\n",
    "\n",
    "**Approach**:\n",
    "- Generate polynomial features for income and evaluate their predictive power against baseline models with linear income terms.\n",
    "- Analyze the impact of the polynomial features on model performance, specifically regarding predictive accuracy for higher-income applicants.\n",
    "- In addition to this there may be predicitve power in binning applicants based on income, this binned feature could then be interacted with other features to capture more granularity in the data\n",
    "\n",
    "----\n",
    "### 3. Hypothesis on Financial Stability and Wealth (particularly for Lower Credit applications)\n",
    "\n",
    "**Hypothesis**: *Individuals purchasing lower-value properties, possibly attempting to stay within perceived financial limits, are likely of lower income and may face a higher risk of default due to lower wealth accumulation and financial stability.*\n",
    "\n",
    "**Rationale**:\n",
    "- EDA indicates a spike in default rates for individuals purchasing properties within the 25-50% price range and in the 25-50% credit range as these two are intrinsically tied together, suggesting these individuals may lack the financial flexibility to absorb unexpected expenses.\n",
    "- Lower-value properties are typically associated with buyers from lower-income brackets, who may experience financial constraints that increase vulnerability to financial shocks.\n",
    "\n",
    "#### Selected Features for Financial Vulnerability and Stability:\n",
    "\n",
    "- **Income / Annuity**  \n",
    "   - **Purpose**: Assesses the income proportion committed to annuity payments.  \n",
    "   - **Hypothesis**: A lower ratio suggests a higher financial burden, indicating less flexibility to absorb unexpected expenses.\n",
    "\n",
    "- **Income / Days Birth**  \n",
    "   - **Purpose**: Proxies for lifetime earning potential relative to age.  \n",
    "   - **Hypothesis**: Lower values imply under-earning for ones age, indicating limited wealth accumulation and resilience.\n",
    "\n",
    "- **Days Employed / Days Birth**  \n",
    "   - **Purpose**: Measures employment stability relative to age.  \n",
    "   - **Hypothesis**: A lower ratio indicates shorter employment durations, signaling possible job instability and financial vulnerability.\n",
    "\n",
    "- **Current Payments Mean / Income**  \n",
    "   - **Purpose**: Reflects the debt load in relation to income.  \n",
    "   - **Hypothesis**: Higher values suggest limited disposable income, making individuals more susceptible to financial shocks.\n",
    "\n",
    "- **Days Employed * Income**  \n",
    "   - **Purpose**: Captures steady income over an extended employment history.  \n",
    "   - **Hypothesis**: Higher values indicate stability and wealth accumulation potential, highlighting individuals with greater resilience even in lower income brackets.\n",
    "\n",
    "These features aim to identify financially vulnerable individuals by modeling the interactions between income, employment stability, and financial commitments, providing insight into their resilience against financial shocks.\n",
    "\n",
    "----\n",
    "\n",
    "### 4. Hypothesis on \"Overextension\" as a key determinant of default risk across all incomes\n",
    "\n",
    "**Hypothesis**: *Overextension financially, loans large relative to income and existing financial strain are key predictors of default*\n",
    "\n",
    "**Rationale**:\n",
    " In the loan application data, defaulters often show loan annuities that are less proportional to their income, suggesting overextension. Financially overextended applicants may be at a higher risk of default, particularly if they lack income flexibility for unexpected expenses. To try and model this I will be looking at credit utilisation in addition to how factors like annuity and requested credit relate to an applicants income.\n",
    "\n",
    "\n",
    "#### Selected Features to Model Overextension (Loan Application Only):\n",
    "\n",
    "1. **Annuity-to-Income Ratio**  \n",
    "   - **Purpose**: Represents the percentage of income dedicated to loan repayments.  \n",
    "   - **Hypothesis**: Higher ratios indicate overextension, as a greater portion of income is allocated to debt servicing, reducing flexibility for other financial needs.\n",
    "\n",
    "2. **Credit-to-Income Ratio**  \n",
    "   - **Purpose**: Measures the requested loan amount relative to income.  \n",
    "   - **Hypothesis**: Higher values suggest a heavier loan burden, indicating that applicants may be overextending themselves relative to their earning capacity.\n",
    "\n",
    "3. **Annuity-to-Credit Ratio**  \n",
    "   - **Purpose**: Reflects the loan terms in relation to the loan size.  \n",
    "   - **Hypothesis**: Lower ratios might indicate longer loan terms with smaller payments, potentially chosen to accommodate affordability, signaling overextension if the applicant struggles with larger debts.\n",
    "\n",
    "4. **Current Payments Mean / Income**  \n",
    "   - **Purpose**: Assesses how much income is allocated toward servicing debt (from payments mean).  \n",
    "   - **Hypothesis**: Higher values indicate limited financial flexibility, as more of the applicants income is used to service debt, elevating default risk if other expenses arise.\n",
    "\n",
    "These features aim to capture overextension solely based on loan size, repayment structure, and income. An applicant exhibiting high values across these metrics is likely at increased risk for default due to overextension within the loan application context, without needing credit card limit data.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Hypothesis on Deviation from Group Norms\n",
    "\n",
    "**Hypothesis**: *Individuals whose financial behaviors significantly deviate from the mean within their categorical groups (e.g., education level, gender, marital status) may exhibit distinct default risk profiles. Calculating deviations from group means for financial metrics will capture these atypical behaviors, enhancing the models ability to detect high-risk applicants.*\n",
    "\n",
    "**Rationale**:\n",
    "- In our EDA few categorical features were informative alone, just knowing marital status doesn't tell you much, however is this due to a lack of granularity in the original features?\n",
    "- Group means for financial metrics within each category (e.g., average income within each education level) can serve as a \"norm\" or baseline.\n",
    "- Individuals who significantly diverge from these norms (e.g., low income within a high-education group) may exhibit different levels of financial stability or risk tolerance than others in their group.\n",
    "- Deviations from these group means can reveal patterns that arent captured by categories alone, allowing for a more granular assessment of financial behavior and risk.\n",
    "\n",
    "**Approach**:\n",
    "- Create mean difference features for groups\n",
    "- Additioanlly interaction features will be created, interacting features like education level, gender, marital status on key numerical features like income, credit limits and so on.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Batch Testing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method\n",
    "- Use a simple logistic regression model to see the impact of partiuclar transformations and created features on model performance for each given hypothesis\n",
    "- Additionally so some features don't overwhelm others given that log reg is sensetive to scale I will be scaling the original dataset, and scaling after any created features or transformations\n",
    "\n",
    "### Evaluation metrics\n",
    "- I will include a range of metrics to evaluate created features on, however the most important features I will be tryng to improve upon here are Recall and AUC score, low precision isn't a massive concern at this stage as ideally through labelling and the meta model, these scores can be improved dramatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Evaluation Function free from data leakage\n",
    "This simple base pipeline can be created and reused for various hypothesis, it's simple it takes in a list of columns to scale and it scales them,\n",
    "\n",
    "This will be used in conjunction with evaluation function, the evaluation function will take, a df, it will split the data, a list of transformations to do or features to create which will also be functions, and then the columns to scale. On each split the respective transformations and scaling is applied.\n",
    "\n",
    "This approach is aimed to prevent data leakage by scaling and creating features exclusively on the train/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Scaling function\n",
    "def scale_columns(df, columns_to_scale, scaler=StandardScaler()):\n",
    "    df = df.copy()  # Avoid mutating the original DataFrame\n",
    "    df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "    return df, scaler  # Return scaler to apply it on test set\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation function with transformations and scaling\n",
    "def evaluate_log_reg_metrics(data, target_column=\"TARGET\", index_column=\"SK_ID_CURR\", \n",
    "                             columns_to_scale=None, transformations=None):\n",
    "    # Separate features and target, excluding the index column\n",
    "    X = data.drop(columns=[target_column, index_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "   \n",
    "    # Apply transformations to both train and test sets separately\n",
    "    if transformations:\n",
    "        for transform in transformations:\n",
    "            X_train = transform(X_train)\n",
    "            X_test = transform(X_test)\n",
    "    \n",
    "    # Scale specified columns in train set and apply same scaler to test set\n",
    "    if columns_to_scale:\n",
    "        X_train, scaler = scale_columns(X_train, columns_to_scale)\n",
    "        X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])  # Apply scaler from train to test\n",
    "\n",
    "    # Define logistic regression model with balanced class weights\n",
    "    model = LogisticRegression(class_weight=\"balanced\", random_state=42, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities and labels\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Create a DataFrame to display metrics\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Metric\": [\"AUC Score\", \"Precision Score\", \"Recall Score\", \"F1 Score\"], \n",
    "        \"Score\": [auc, precision, recall, f1]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nLogistic Regression Model Evaluation:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "\n",
    "\n",
    "    \"\"\" Example Usage\n",
    "\n",
    "    evaluate_log_reg_metrics(data=df, target_column=\"TARGET\", index_column=\"SK_ID_CURR\",\n",
    "                         columns_to_scale=columns_to_scale, transformations=transformations)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1: \"Correcting for Right Skew will improve model performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " evaluation with log transforms (scaled):\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.745618\n",
      "Precision Score 0.175703\n",
      "   Recall Score 0.662197\n",
      "       F1 Score 0.277718\n",
      "\n",
      " evaluation no log transforms (scaled):\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.744523\n",
      "Precision Score 0.175465\n",
      "   Recall Score 0.668582\n",
      "       F1 Score 0.277977\n",
      "\n",
      " evaluation no log transforms (not scaled):\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.662458\n",
      "Precision Score 0.150269\n",
      "   Recall Score 0.553001\n",
      "       F1 Score 0.236321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "default_columns_to_scale = [\n",
    "    'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'DAYS_ID_PUBLISH',\n",
    "    'DAYS_REGISTRATION', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'DAYS_LAST_PHONE_CHANGE',\n",
    "    'AMT_CREDIT', 'REGION_POPULATION_RELATIVE', 'AMT_INCOME_TOTAL', 'AMT_GOODS_PRICE',\n",
    "    'EXT_SOURCE_1', 'HOUR_APPR_PROCESS_START', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n",
    "    'OWN_CAR_AGE', 'LIVINGAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', \n",
    "    'OBS_30_CNT_SOCIAL_CIRCLE', 'APARTMENTS_AVG', 'OBS_60_CNT_SOCIAL_CIRCLE', \n",
    "    'CNT_FAM_MEMBERS', 'COMMONAREA_AVG', 'YEARS_BUILD_AVG', 'NONLIVINGAREA_AVG', \n",
    "    'LANDAREA_AVG', 'BASEMENTAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'CNT_CHILDREN',\n",
    "    'TOTAL_DOCUMENT_FLAGS', 'STABILITY_INDEX', 'CONTACT_INDEX', \n",
    "    'CREDIT_BUREAU_REQ_TOTAL', 'SOCIAL_CIRCLE_OBS_TOTAL', 'SOCIAL_CIRCLE_DEF_TOTAL',\n",
    "    'AMT_PAYMENT_CURRENT_mean', 'AMT_DRAWINGS_OTHER_CURRENT_sum', \n",
    "    'CNT_DRAWINGS_ATM_CURRENT_sum', 'AMT_TOTAL_RECEIVABLE_mean', 'AMT_BALANCE_mean',\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL_mean', 'SK_ID_PREV_count', 'AMT_INST_MIN_REGULARITY_mean', \n",
    "    'AMT_RECIVABLE_mean', 'AMT_RECEIVABLE_PRINCIPAL_mean', 'AMT_RECIVABLE_sum',\n",
    "    'AMT_RECEIVABLE_PRINCIPAL_sum', 'CNT_INSTALMENT_MATURE_CUM_sum', \n",
    "    'MONTHS_BALANCE_max', 'SK_DPD_max', 'SK_DPD_DEF_max', 'Payment_Behavior_Index'\n",
    "]\n",
    "\n",
    "def correct_right_skew(df):\n",
    "    import numpy as np\n",
    "\n",
    "    # Right-skewed features identified in EDA\n",
    "    right_skewed_columns = [\n",
    "        'AMT_ANNUITY', 'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'AMT_GOODS_PRICE', \n",
    "        'AMT_REQ_CREDIT_BUREAU_YEAR', 'AMT_PAYMENT_CURRENT_mean', 'AMT_DRAWINGS_OTHER_CURRENT_sum', \n",
    "        'CNT_DRAWINGS_ATM_CURRENT_sum', 'AMT_TOTAL_RECEIVABLE_mean', 'AMT_BALANCE_mean', \n",
    "        'AMT_CREDIT_LIMIT_ACTUAL_mean', 'AMT_INST_MIN_REGULARITY_mean', 'AMT_RECIVABLE_mean', \n",
    "        'AMT_RECEIVABLE_PRINCIPAL_mean', 'AMT_RECIVABLE_sum', 'AMT_RECEIVABLE_PRINCIPAL_sum', \n",
    "        'CNT_INSTALMENT_MATURE_CUM_sum']                    \n",
    "\n",
    "    df = df.copy()\n",
    "    for col in right_skewed_columns:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "h1_transforms = [correct_right_skew]\n",
    "\n",
    "print(\" \\n evaluation with log transforms (scaled):\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=default_columns_to_scale, transformations=h1_transforms)\n",
    "print(\"\\n evaluation no log transforms (scaled):\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=default_columns_to_scale)\n",
    "print(\"\\n evaluation no log transforms (not scaled):\")\n",
    "evaluate_log_reg_metrics(merged_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Log Transformation and Scaling in Model Performance\n",
    "\n",
    "Below is a performance comparison across three configurations: **log-transformed and scaled**, **scaled without log transformation**, and **no transformations**. The table illustrates gains in **AUC**, **Precision**, **Recall**, and **F1 Score** from each configuration relative to the preceding one.\n",
    "\n",
    "#### Model Performance\n",
    "\n",
    "| Metric          | Log-Transformed + Scaled | Scaled Only | No Transforms + Not Scaled | Gain (Log-Scaled vs. Scaled Only) | Gain (Scaled vs. No Transforms) |\n",
    "|-----------------|--------------------------|-------------|----------------------------|------------------------------------|----------------------------------|\n",
    "| **AUC Score**   | 0.7456                   | 0.7445      | 0.6625                     | +0.15%                             | +12.38%                          |\n",
    "| **Precision**   | 0.1757                   | 0.1755      | 0.1503                     | +0.14%                             | +16.83%                          |\n",
    "| **Recall**      | 0.6622                   | 0.6686      | 0.5530                     | -0.95%                             | +20.91%                          |\n",
    "| **F1 Score**    | 0.2777                   | 0.2780      | 0.2363                     | -0.11%                             | +17.64%                          |\n",
    "\n",
    "#### Key Observations\n",
    "\n",
    "1. **AUC Score**:\n",
    "   - **Scaling Only** and **Log-Scaled Transformation** both produced significant AUC gains over the untransformed dataset, with **log transformation** providing an additional 0.15% gain.\n",
    "   - A notable 12.38% AUC improvement occurred from applying scaling to the untransformed data, underscoring scaling's importance for model convergence.\n",
    "\n",
    "2. **Precision**:\n",
    "   - **Precision** experienced minimal gains from log transformation, showing a slight 0.14% increase.\n",
    "   - Compared to the untransformed dataset, scaling alone improved precision by 16.83%.\n",
    "\n",
    "3. **Recall**:\n",
    "   - Interestingly, recall decreased by 0.95% with the addition of log transformation, but scaling alone provided a substantial recall gain of 20.91% over the untransformed baseline.\n",
    "\n",
    "4. **F1 Score**:\n",
    "   - The F1 score was largely consistent across configurations, with a marginal 0.11% decrease with log transformation.\n",
    "   - From the untransformed dataset, scaling improved F1 score by 17.64%, showing the balance achieved with scaling alone.\n",
    "\n",
    "**Conclusion**:  \n",
    "The results indicate that **scaling without log transformation** provides the most balanced performance gains across recall and F1 score, while **log transformation offers a modest boost in AUC**. These findings suggest that, for this model, scaling alone is sufficient to achieve optimal performance gains without compromising recall or F1 balance.\n",
    "\n",
    "#### Hypothesis 1: \"Correcting for Right Skew will improve model performance\"\n",
    "\n",
    "Based on this analysis, **Hypothesis 1 is only partially supported**. Correcting for right skew with log transformations slightly improves AUC but does not yield substantial gains in precision, recall, or F1 score beyond what scaling alone achieves. This suggests that, while addressing skewness may help in certain metrics, it does not significantly impact overall performance in this context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hypothesis on Non-linear Relationship between Income and Default Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " evaluation with h2 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.744515\n",
      "Precision Score 0.177425\n",
      "   Recall Score 0.670498\n",
      "       F1 Score 0.280599\n",
      " \n",
      " evaluation without h2 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.744523\n",
      "Precision Score 0.175465\n",
      "   Recall Score 0.668582\n",
      "       F1 Score 0.277977\n",
      " \n",
      " evaluation with h2 features created after log scaling:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.745358\n",
      "Precision Score 0.176772\n",
      "   Recall Score 0.660920\n",
      "       F1 Score 0.278938\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#function to create features:\n",
    "def non_linear_income_features(df):\n",
    "    \"\"\"\n",
    "    Create income quartile-based features for default risk prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - The DataFrame to add features to. Requires columns for AMT_INCOME_TOTAL, AMT_CREDIT, etc.\n",
    "    \n",
    "    Returns:\n",
    "    - df: pd.DataFrame - DataFrame with new income quartile-based features added.\n",
    "    \"\"\"\n",
    "    # Create income quartile feature\n",
    "    df['AMT_INCOME_QUARTILE'] = pd.qcut(df['AMT_INCOME_TOTAL'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    df['AMT_INCOME_QUARTILE'] = df['AMT_INCOME_QUARTILE'].map({'Q1': 1, 'Q2': 2, 'Q3': 3, 'Q4': 4}).astype(float)\n",
    "\n",
    "    # Interaction and derived features\n",
    "    df['AMT_INCOME_TOTAL_squared'] = df['AMT_INCOME_TOTAL'] ** 2\n",
    "    df['INCOME_BIN_CREDIT'] = df['AMT_INCOME_QUARTILE'] * df['AMT_CREDIT']\n",
    "    df['INCOME_QUARTILE_ANNUITY_RATIO'] = df['AMT_INCOME_QUARTILE'] * df['AMT_ANNUITY']\n",
    "    df['INCOME_QUARTILE_EMPLOYED_RATIO'] = df['AMT_INCOME_QUARTILE'] * df['DAYS_EMPLOYED']\n",
    "    df['INCOME_QUARTILE_EXT_SOURCE2'] = df['AMT_INCOME_QUARTILE'] * df['EXT_SOURCE_2']\n",
    "    df['INCOME_QUARTILE_EXT_SOURCE3'] = df['AMT_INCOME_QUARTILE'] * df['EXT_SOURCE_3']\n",
    "    df['INCOME_QUARTILE_AGE'] = df['AMT_INCOME_QUARTILE'] * abs(df['DAYS_BIRTH'])\n",
    "    df['INCOME_QUARTILE_DEBT_RATIO'] = df['AMT_INCOME_QUARTILE'] * (df['AMT_CREDIT'] / (df['AMT_INCOME_TOTAL'] + 1e-5))\n",
    "    df['INCOME_CREDIT_HISTORY_STABILITY'] = df['AMT_INCOME_QUARTILE'] * (df['SK_DPD_max'] + df['SK_DPD_DEF_max'])\n",
    "    df['INCOME_DEBT_BURDEN_INDEX'] = df['AMT_INCOME_QUARTILE'] * (df['AMT_ANNUITY'] + df['AMT_TOTAL_RECEIVABLE_mean']) / (df['AMT_INCOME_TOTAL'] + 1e-5)\n",
    "    df['DEBT_TO_CREDIT_QUARTILE'] = df['AMT_INCOME_QUARTILE'] * (df['AMT_CREDIT'] / (df['AMT_ANNUITY'] + 1e-5))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Updated list of columns to scale, including any new columns in nl_df\n",
    "h2_features =  ['AMT_INCOME_TOTAL_squared', 'INCOME_BIN_CREDIT', 'INCOME_QUARTILE_ANNUITY_RATIO', 'INCOME_QUARTILE_EMPLOYED_RATIO',\n",
    "    'INCOME_QUARTILE_EXT_SOURCE2', 'INCOME_QUARTILE_EXT_SOURCE3', 'INCOME_QUARTILE_AGE', 'INCOME_QUARTILE_DEBT_RATIO',\n",
    "    'INCOME_CREDIT_HISTORY_STABILITY', 'INCOME_DEBT_BURDEN_INDEX', 'DEBT_TO_CREDIT_QUARTILE']\n",
    "h2_columns_to_scale = default_columns_to_scale + h2_features\n",
    "h2_transforms = [non_linear_income_features]\n",
    "\n",
    "\n",
    "\n",
    "print(\" \\n evaluation with h2 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=h2_columns_to_scale, transformations=h2_transforms)\n",
    "\n",
    "print(\" \\n evaluation without h2 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=default_columns_to_scale)\n",
    "\n",
    "h2_transforms = [correct_right_skew, non_linear_income_features]\n",
    "### Does log scaling improve created features\n",
    "print(\" \\n evaluation with h2 features created after log scaling:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=h2_columns_to_scale, transformations=h2_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Hypothesis 2: Impact of Non-linear Relationship Features with Log Scaling\n",
    "\n",
    "This section evaluates the impact of creating new non-linear relationship features, both with and without prior log scaling of specific variables. Hypothesis 2 assumes that adding non-linear features based on income quartiles will improve model performance by capturing nuanced relationships between income and default risk.\n",
    "\n",
    "#### Model Performance Comparisons\n",
    "\n",
    "| Evaluation Configuration                  | AUC Score | Precision | Recall   | F1 Score | Gain in AUC (%) | Gain in Precision (%) | Gain in Recall (%) | Gain in F1 Score (%) |\n",
    "|-------------------------------------------|-----------|-----------|----------|----------|-----------------|-----------------------|--------------------|-----------------------|\n",
    "| **Without H2 Features**                   | 0.744523  | 0.175465  | 0.668582 | 0.277977 | -               | -                     | -                  | -                     |\n",
    "| **With H2 Features**                      | 0.744515  | 0.177425  | 0.670498 | 0.280599 | -0.001%         | +1.12%                | +0.29%             | +0.94%                |\n",
    "| **With H2 Features After Log Scaling**    | 0.745358  | 0.176772  | 0.660920 | 0.278938 | +0.11%          | +0.74%                | -1.15%             | +0.35%                |\n",
    "\n",
    "#### Key Observations\n",
    "\n",
    "1. **AUC Score**:\n",
    "   - Adding H2 features alone led to a modest reduction in AUC by -0.001%.\n",
    "   - Applying log scaling before creating H2 features showed a modest gain in AUC, from 0.744523 (baseline) to 0.745358, representing a gain of +0.11%.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Precision improved modestly when H2 features were added, with a gain of +1.12%.\n",
    "   - Log scaling before creating H2 features provided a precision gain of +0.74% over the baseline.\n",
    "\n",
    "3. **Recall**:\n",
    "   - Recall saw a modest gain with H2 features alone (+0.29%).\n",
    "   - After log scaling, recall decreased to 0.660920, reflecting a loss of -1.15% compared to the baseline.\n",
    "\n",
    "4. **F1 Score**:\n",
    "   - The F1 score improved with H2 features alone, showing a gain of +0.94%.\n",
    "   - After log scaling, the F1 score landed at 0.278938, a modest gain of +0.35% over the baseline.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The addition of non-linear relationship features (Hypothesis 2) provided modest improvements across the performance metrics, with notable gains in precision and F1 score. Applying log scaling before creating H2 features modestly increased AUC but did not lead to significant improvements in other metrics. This suggests that while non-linear transformations based on income quartiles capture some additional predictive nuance, their impact remains modest, and further refinement or feature selection may enhance these features' effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 3: Modeling Wealth Accumulation and Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " evaluation with h3 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.745991\n",
      "Precision Score 0.177384\n",
      "   Recall Score 0.671137\n",
      "       F1 Score 0.280603\n",
      " \n",
      " evaluation without h3 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.744523\n",
      "Precision Score 0.175465\n",
      "   Recall Score 0.668582\n",
      "       F1 Score 0.277977\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_wealth_features(df):\n",
    "    \"\"\"\n",
    "    Creates new wealth-related features directly on the provided DataFrame.\n",
    "    \"\"\"\n",
    "    # Create new features directly in the input DataFrame\n",
    "    quartile_threshold = df['AMT_GOODS_PRICE'].quantile(0.25)\n",
    "    df['binary_feature'] = (df['AMT_GOODS_PRICE'] <= quartile_threshold).astype(int)\n",
    "    df['income_annuity_ratio'] = df['AMT_INCOME_TOTAL'] / df['AMT_ANNUITY']\n",
    "    df['income_days_birth_ratio'] = df['AMT_INCOME_TOTAL'] / (-df['DAYS_BIRTH'])\n",
    "    df['days_employed_days_birth_ratio'] = df['DAYS_EMPLOYED'] / (-df['DAYS_BIRTH'])\n",
    "    df['current_payments_income_ratio'] = df['AMT_PAYMENT_CURRENT_mean'] / df['AMT_INCOME_TOTAL']\n",
    "    df['days_employed_income_product'] = df['DAYS_EMPLOYED'] * df['AMT_INCOME_TOTAL']\n",
    "    df['financial_flexibility_score'] = (df['AMT_INCOME_TOTAL'] - df['AMT_PAYMENT_CURRENT_mean']) / df['AMT_GOODS_PRICE']\n",
    "    df['dependency_load_index'] = df['CNT_CHILDREN'] / df['CNT_FAM_MEMBERS']\n",
    "    return df\n",
    "\n",
    "\n",
    "h3_features = [\n",
    "    ### new stuff\n",
    "    'Payment_Behavior_Index', 'financial_flexibility_score', 'dependency_load_index', 'days_employed_days_birth_ratio', 'income_annuity_ratio', 'income_days_birth_ratio',\n",
    "    'current_payments_income_ratio', 'days_employed_income_product',\n",
    "]\n",
    "h3_columns_to_scale = default_columns_to_scale + h3_features\n",
    "h3_transforms = [create_wealth_features]\n",
    "\n",
    "print(\" \\n evaluation with h3 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=h3_columns_to_scale, transformations=h3_transforms)\n",
    "\n",
    "print(\" \\n evaluation without h3 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=default_columns_to_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Hypothesis 3: Impact of Feature Set H3 on Model Performance\n",
    "\n",
    "### Model Performance Comparisons\n",
    "\n",
    "| Evaluation Configuration  | AUC Score | Precision | Recall   | F1 Score | Gain in AUC (%) | Gain in Precision (%) | Gain in Recall (%) | Gain in F1 Score (%) |\n",
    "|---------------------------|-----------|-----------|----------|----------|-----------------|-----------------------|--------------------|-----------------------|\n",
    "| **Without H3 Features**   | 0.744523  | 0.175465  | 0.668582 | 0.277977 | -               | -                     | -                  | -                     |\n",
    "| **With H3 Features**      | 0.745991  | 0.177384  | 0.671137 | 0.280603 | +0.20%          | +1.10%                | +0.38%             | +0.94%                |\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **AUC Score**:\n",
    "   - Adding H3 features resulted in a slight increase in AUC by +0.20%, indicating a marginal improvement in the model's ability to distinguish between classes.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Precision improved by +1.10%, suggesting that the H3 features slightly increased the model's ability to correctly predict positive cases relative to total predicted positives.\n",
    "\n",
    "3. **Recall**:\n",
    "   - Recall saw a small gain of +0.38%, meaning the model captured a slightly higher proportion of actual positives with the H3 features.\n",
    "\n",
    "4. **F1 Score**:\n",
    "   - The F1 score also improved by +0.94%, showing a balanced improvement in both precision and recall due to the added H3 features.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The addition of H3 features led to modest gains across all performance metrics, with the most notable improvement in precision. This suggests that the H3 feature set added valuable predictive nuance, though the overall impact remains relatively moderate. Further refinement or expansion of feature engineering might yield stronger performance gains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Overextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " evaluation with h4 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.745935\n",
      "Precision Score 0.177508\n",
      "   Recall Score 0.662197\n",
      "       F1 Score 0.279968\n",
      " \n",
      " evaluation without h4 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.744523\n",
      "Precision Score 0.175465\n",
      "   Recall Score 0.668582\n",
      "       F1 Score 0.277977\n"
     ]
    }
   ],
   "source": [
    "def overextension_features(df):\n",
    "    \"\"\"\n",
    "    Adds overextension-related features to the given DataFrame in place.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame to modify with overextension features.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The modified DataFrame with new features added.\n",
    "    \"\"\"\n",
    "    # 1. Annuity-to-Income Ratio\n",
    "    df['annuity_income_ratio'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # 2. Credit-to-Income Ratio\n",
    "    df['credit_income_ratio'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # 3. Annuity-to-Credit Ratio\n",
    "    df['annuity_credit_ratio'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    \n",
    "    # 4. Current Payments Mean to Income Ratio\n",
    "    df['current_payments_income_ratio'] = df['AMT_PAYMENT_CURRENT_mean'] / df['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # 5. Credit Utilization Ratio\n",
    "    df['credit_utilization_ratio'] = df['AMT_BALANCE_mean'] / df['AMT_CREDIT_LIMIT_ACTUAL_mean']\n",
    "    \n",
    "    # 6. Debt-to-Asset Ratio\n",
    "    df['debt_asset_ratio'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "h4_features = ['annuity_income_ratio', 'credit_income_ratio', 'annuity_credit_ratio', 'current_payments_income_ratio', 'debt_asset_ratio', 'credit_utilization_ratio']\n",
    "h4_columns_to_scale = default_columns_to_scale + h4_features\n",
    "h4_transforms = [overextension_features]\n",
    "\n",
    "\n",
    "print(\" \\n evaluation with h4 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=h4_columns_to_scale, transformations=h4_transforms)\n",
    "\n",
    "print(\" \\n evaluation without h4 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=default_columns_to_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Hypothesis 4: Impact of Additional Ratio Features on Model Performance\n",
    "\n",
    "\n",
    "### Model Performance Comparisons\n",
    "\n",
    "| Evaluation Configuration  | AUC Score | Precision | Recall   | F1 Score | Gain in AUC (%) | Gain in Precision (%) | Gain in Recall (%) | Gain in F1 Score (%) |\n",
    "|---------------------------|-----------|-----------|----------|----------|-----------------|-----------------------|--------------------|-----------------------|\n",
    "| **Without H4 Features**   | 0.744523  | 0.175465  | 0.668582 | 0.277977 | -               | -                     | -                  | -                     |\n",
    "| **With H4 Features**      | 0.745935  | 0.177508  | 0.662197 | 0.279968 | +0.19%          | +1.16%                | -0.95%             | +0.72%                |\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **AUC Score**:\n",
    "   - The addition of H4 features led to a slight increase in AUC by +0.19%, showing a small improvement in the models ability to discriminate between classes.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Precision improved by +1.16%, indicating a modest improvement in the models ratio of true positives to predicted positives with the H4 features.\n",
    "\n",
    "3. **Recall**:\n",
    "   - Recall decreased slightly by -0.95%, meaning the model captured a marginally lower proportion of actual positives after adding H4 features.\n",
    "\n",
    "4. **F1 Score**:\n",
    "   - The F1 score showed a slight improvement of +0.72%, suggesting a balanced gain in both precision and recall with the added features.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The inclusion of H4 features provided modest gains in AUC, precision, and F1 score, with a small trade-off in recall. These results suggest that the additional ratio features in H4 capture some useful patterns, particularly improving precision. Overall, the H4 features show potential for enhancing model performance, though further optimization may yield more substantial gains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deviation from group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " evaluation with h5 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.744772\n",
      "Precision Score 0.175521\n",
      "   Recall Score 0.666667\n",
      "       F1 Score 0.277881\n",
      " \n",
      " evaluation without h5 features:\n",
      "\n",
      "Logistic Regression Model Evaluation:\n",
      "         Metric    Score\n",
      "      AUC Score 0.744523\n",
      "Precision Score 0.175465\n",
      "   Recall Score 0.668582\n",
      "       F1 Score 0.277977\n"
     ]
    }
   ],
   "source": [
    "def group_deviation_features(df):\n",
    "    \"\"\"\n",
    "    Adds group deviation features to the DataFrame. For each column in financial_columns,\n",
    "    this function calculates the deviation of each value from the group mean based on each\n",
    "    grouping variable in group_columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to modify with new deviation features.\n",
    "    financial_columns (list of str): List of column names to calculate deviations for.\n",
    "    group_columns (list of str): List of columns to group by.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The modified DataFrame with added deviation features.\n",
    "    \"\"\"\n",
    "\n",
    "    # List of financial columns to create group deviation features for\n",
    "    financial_columns = ['AMT_GOODS_PRICE', 'AMT_ANNUITY', 'AMT_CREDIT', 'AMT_CREDIT_LIMIT_ACTUAL_mean']\n",
    "\n",
    "    # Grouping columns\n",
    "    group_columns = ['NAME_EDUCATION_TYPE', 'CODE_GENDER', 'NAME_FAMILY_STATUS_Married']\n",
    "\n",
    "    for group_col in group_columns:\n",
    "        for col in financial_columns:\n",
    "            group_mean = df.groupby(group_col)[col].transform('mean')\n",
    "            df[f'{col}_deviation_from_{group_col}_mean'] = df[col] - group_mean\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "h5_features = [\n",
    "    'AMT_GOODS_PRICE_deviation_from_NAME_EDUCATION_TYPE_mean',\n",
    "    'AMT_ANNUITY_deviation_from_NAME_EDUCATION_TYPE_mean',\n",
    "    'AMT_CREDIT_deviation_from_NAME_EDUCATION_TYPE_mean',\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL_mean_deviation_from_NAME_EDUCATION_TYPE_mean',\n",
    "    'AMT_GOODS_PRICE_deviation_from_CODE_GENDER_mean',\n",
    "    'AMT_ANNUITY_deviation_from_CODE_GENDER_mean',\n",
    "    'AMT_CREDIT_deviation_from_CODE_GENDER_mean',\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL_mean_deviation_from_CODE_GENDER_mean',\n",
    "    'AMT_GOODS_PRICE_deviation_from_NAME_FAMILY_STATUS_Married_mean',\n",
    "    'AMT_ANNUITY_deviation_from_NAME_FAMILY_STATUS_Married_mean',\n",
    "    'AMT_CREDIT_deviation_from_NAME_FAMILY_STATUS_Married_mean',\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL_mean_deviation_from_NAME_FAMILY_STATUS_Married_mean'\n",
    "]\n",
    "h5_columns_to_scale = default_columns_to_scale + h5_features\n",
    "h5_transforms = [group_deviation_features]\n",
    "\n",
    "\n",
    "print(\" \\n evaluation with h5 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=h5_columns_to_scale, transformations=h5_transforms)\n",
    "\n",
    "print(\" \\n evaluation without h5 features:\")\n",
    "evaluate_log_reg_metrics(merged_train_df, columns_to_scale=default_columns_to_scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Hypothesis 5: Impact of Group Deviation Features on Model Performance\n",
    "\n",
    "### Model Performance Comparisons\n",
    "\n",
    "| Evaluation Configuration  | AUC Score | Precision | Recall   | F1 Score | Gain in AUC (%) | Gain in Precision (%) | Gain in Recall (%) | Gain in F1 Score (%) |\n",
    "|---------------------------|-----------|-----------|----------|----------|-----------------|-----------------------|--------------------|-----------------------|\n",
    "| **Without H5 Features**   | 0.744523  | 0.175465  | 0.668582 | 0.277977 | -               | -                     | -                  | -                     |\n",
    "| **With H5 Features**      | 0.744772  | 0.175521  | 0.666667 | 0.277881 | +0.03%          | +0.03%                | -0.29%             | -0.03%                |\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **AUC Score**:\n",
    "   - The inclusion of H5 features led to a slight increase in AUC by +0.03%, suggesting a negligible improvement in model discrimination.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Precision saw a minor gain of +0.03%, indicating a marginally improved rate of true positives to predicted positives with H5 features.\n",
    "\n",
    "3. **Recall**:\n",
    "   - Recall decreased slightly by -0.29%, meaning the model captured a marginally lower proportion of actual positives after adding H5 features.\n",
    "\n",
    "4. **F1 Score**:\n",
    "   - The F1 score showed a negligible decrease of -0.03%, suggesting that the addition of H5 features had a minimal overall impact on balancing precision and recall.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The addition of group deviation features (H5) led to minor changes across all metrics, with a negligible increase in AUC and precision but a slight decrease in recall and F1 score. This suggests that while the group deviation features capture some information about group-specific deviations, their impact on overall model performance is limited. Further experimentation with more granular grouping variables or additional feature engineering may be needed to enhance predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Custom transformer for scaling columns\n",
    "class ScaleColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns_to_scale):\n",
    "        self.columns_to_scale = columns_to_scale\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns_to_scale])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.columns_to_scale] = self.scaler.transform(X[self.columns_to_scale])\n",
    "        return X\n",
    "\n",
    "# Custom transformer for non-linear income features\n",
    "class NonLinearIncomeFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return non_linear_income_features(X)\n",
    "\n",
    "# Custom transformer for wealth-related features\n",
    "class WealthFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return create_wealth_features(X)\n",
    "\n",
    "# Custom transformer for overextension-related features\n",
    "class OverextensionFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        return overextension_features(X)\n",
    "    \n",
    "class SetIndex(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, index_column):\n",
    "        self.index_column = index_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X.set_index(self.index_column, inplace=True)\n",
    "        return X\n",
    "\n",
    "# Define the feature engineering pipeline\n",
    "def create_feature_engineering_pipeline(columns_to_scale, index_column=\"SK_ID_CURR\"):\n",
    "    feature_pipeline = Pipeline([\n",
    "        ('non_linear_income_features', NonLinearIncomeFeatures()),\n",
    "        ('wealth_features', WealthFeatures()),\n",
    "        ('overextension_features', OverextensionFeatures()),\n",
    "        ('scaling', ScaleColumns(columns_to_scale=columns_to_scale)),\n",
    "        ('set_index', SetIndex(index_column=index_column))\n",
    "        \n",
    "    ])\n",
    "    return feature_pipeline\n",
    "\n",
    "\n",
    "# Assuming you have a DataFrame `df` with the required columns\n",
    "# columns_to_scale = ['your', 'column', 'names']  # specify the columns you want to scale\n",
    "# pipeline = create_feature_engineering_pipeline(columns_to_scale=columns_to_scale)\n",
    "# transformed_df = pipeline.fit_transform(df)\n",
    "\n",
    "\n",
    "all_columns_to_scale = ['EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'DAYS_LAST_PHONE_CHANGE', 'AMT_CREDIT', 'REGION_POPULATION_RELATIVE', 'AMT_INCOME_TOTAL', 'AMT_GOODS_PRICE', 'EXT_SOURCE_1', 'HOUR_APPR_PROCESS_START', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'OWN_CAR_AGE', 'LIVINGAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'OBS_30_CNT_SOCIAL_CIRCLE', 'APARTMENTS_AVG', 'OBS_60_CNT_SOCIAL_CIRCLE', 'CNT_FAM_MEMBERS', 'COMMONAREA_AVG', 'YEARS_BUILD_AVG', 'NONLIVINGAREA_AVG', 'LANDAREA_AVG', 'BASEMENTAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'CNT_CHILDREN', 'TOTAL_DOCUMENT_FLAGS', 'STABILITY_INDEX', 'CONTACT_INDEX', 'CREDIT_BUREAU_REQ_TOTAL', 'SOCIAL_CIRCLE_OBS_TOTAL', 'SOCIAL_CIRCLE_DEF_TOTAL', 'AMT_PAYMENT_CURRENT_mean', 'AMT_DRAWINGS_OTHER_CURRENT_sum', 'CNT_DRAWINGS_ATM_CURRENT_sum', 'AMT_TOTAL_RECEIVABLE_mean', 'AMT_BALANCE_mean', 'AMT_CREDIT_LIMIT_ACTUAL_mean', 'SK_ID_PREV_count', 'AMT_INST_MIN_REGULARITY_mean', 'AMT_RECIVABLE_mean', 'AMT_RECEIVABLE_PRINCIPAL_mean', 'AMT_RECIVABLE_sum', 'AMT_RECEIVABLE_PRINCIPAL_sum', 'CNT_INSTALMENT_MATURE_CUM_sum', 'MONTHS_BALANCE_max', 'SK_DPD_max', 'SK_DPD_DEF_max', 'Payment_Behavior_Index', 'AMT_INCOME_TOTAL_squared', 'INCOME_BIN_CREDIT', 'INCOME_QUARTILE_ANNUITY_RATIO', 'INCOME_QUARTILE_EMPLOYED_RATIO', 'INCOME_QUARTILE_EXT_SOURCE2', 'INCOME_QUARTILE_EXT_SOURCE3', 'INCOME_QUARTILE_AGE', 'INCOME_QUARTILE_DEBT_RATIO', 'INCOME_CREDIT_HISTORY_STABILITY', 'INCOME_DEBT_BURDEN_INDEX', 'DEBT_TO_CREDIT_QUARTILE', 'Payment_Behavior_Index', 'financial_flexibility_score', 'dependency_load_index', 'days_employed_days_birth_ratio', 'income_annuity_ratio', 'income_days_birth_ratio', 'current_payments_income_ratio', 'days_employed_income_product', 'annuity_income_ratio', 'credit_income_ratio', 'annuity_credit_ratio', 'current_payments_income_ratio', 'debt_asset_ratio', 'credit_utilization_ratio']\n",
    "\n",
    "FE_pipeline = create_feature_engineering_pipeline(all_columns_to_scale)\n",
    "\n",
    "FE_merged_train_df = FE_pipeline.fit_transform(merged_train_df)\n",
    "FE_merged_val_df = FE_pipeline.fit_transform(merged_val_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting and Optimal Feature Set with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_features \u001b[38;5;129;01min\u001b[39;00m n_features_list:\n\u001b[0;32m     40\u001b[0m     rfe \u001b[38;5;241m=\u001b[39m RFE(model, n_features_to_select\u001b[38;5;241m=\u001b[39mn_features)\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Select the features and prepare train and validation sets\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     selected_features \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns[rfe\u001b[38;5;241m.\u001b[39msupport_]\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:268\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    267\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:323\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 323\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    326\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    327\u001b[0m     estimator,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    329\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    330\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:455\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    451\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    452\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    453\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    454\u001b[0m ]\n\u001b[1;32m--> 455\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    470\u001b[0m     solver,\n\u001b[0;32m    471\u001b[0m     opt_res,\n\u001b[0;32m    472\u001b[0m     max_iter,\n\u001b[0;32m    473\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    475\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    728\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    729\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 731\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    734\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    735\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:343\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[1;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 294\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:281\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n\u001b[1;32m--> 281\u001b[0m loss, grad_pointwise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m sw_sum \u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(sample_weight)\n\u001b[0;32m    288\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m sw_sum\n",
      "File \u001b[1;32mc:\\Users\\david\\Projects\\Credit_Risk_Project\\Credit_Risk_venv\\Lib\\site-packages\\sklearn\\_loss\\loss.py:202\u001b[0m, in \u001b[0;36mBaseLoss.loss_gradient\u001b[1;34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss\u001b[38;5;241m.\u001b[39mloss(\n\u001b[0;32m    194\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[0;32m    195\u001b[0m         raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_out\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_gradient\u001b[39m(\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    204\u001b[0m     y_true,\n\u001b[0;32m    205\u001b[0m     raw_prediction,\n\u001b[0;32m    206\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    207\u001b[0m     loss_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    208\u001b[0m     gradient_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    210\u001b[0m ):\n\u001b[0;32m    211\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \n\u001b[0;32m    213\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m        Element-wise gradients.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate features and target in the train and validation sets\n",
    "X_train = FE_merged_train_df.drop(columns=[\"TARGET\"])\n",
    "y_train = FE_merged_train_df[\"TARGET\"]\n",
    "X_val = FE_merged_val_df.drop(columns=[\"TARGET\"])\n",
    "y_val = FE_merged_val_df[\"TARGET\"]\n",
    "\n",
    "# Initialize model\n",
    "model = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "n_features_list = range(10, X_train.shape[1], 10)  # Testing every 10 features\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Function to evaluate precision, recall, and f1\n",
    "def evaluate_precision_recall_f1(X_train, y_train, X_val, y_val):\n",
    "    # Train logistic regression model\n",
    "    model = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Loop over different numbers of features for RFE\n",
    "for n_features in n_features_list:\n",
    "    rfe = RFE(model, n_features_to_select=n_features)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    \n",
    "    # Select the features and prepare train and validation sets\n",
    "    selected_features = X_train.columns[rfe.support_]\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_val_selected = X_val[selected_features]\n",
    "    \n",
    "    # Evaluate model performance with selected features\n",
    "    precision, recall, f1 = evaluate_precision_recall_f1(X_train_selected, y_train, X_val_selected, y_val)\n",
    "    \n",
    "    # Store the results\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Plot Precision, Recall, and F1 Score against the number of features\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_features_list, precision_scores, label=\"Precision\", marker='o')\n",
    "plt.plot(n_features_list, recall_scores, label=\"Recall\", marker='o')\n",
    "plt.plot(n_features_list, f1_scores, label=\"F1 Score\", marker='o')\n",
    "plt.xlabel(\"Number of Selected Features\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, and F1 Score vs. Number of Selected Features\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Choice: 40 Features\n",
    "\n",
    "After analyzing the Precision, Recall, and F1 Score trends across different numbers of selected features, I chose to use **40 features** for the following reasons:\n",
    "\n",
    "1. **Maximizing Recall and F1 Score**:\n",
    "   - The plot of Precision, Recall, and F1 Score against the number of features shows a slight uptick in Recall and F1 Score around the 40-feature mark. Although Recall and F1 initially plateau around 10-15 features, this secondary increase at 40 features suggests that additional predictive information is being captured, particularly for identifying positive cases.\n",
    "   - Since my primary objective is to maximize the models ability to identify positives (high Recall) while maintaining a balanced performance (high F1 Score), selecting 40 features allows me to capture these small but meaningful improvements.\n",
    "\n",
    "2. **Balancing Complexity and Performance Gains**:\n",
    "   - While using fewer features (10-15) could simplify the model, the minor performance gain at 40 features is valuable in this context, as it could enhance the model's robustness without a substantial increase in complexity.\n",
    "   - By selecting 40 features, I aim to achieve an optimized balance between model complexity and predictive power, capturing nuanced patterns that may not be as evident with fewer features.\n",
    "\n",
    "3. **Focus on Small Gains**:\n",
    "   - Although the improvements are incremental, the secondary spike in Recall and F1 at 40 features justifies the decision to prioritize every possible gain. This choice reflects an optimization approach that values incremental improvements in predictive performance, even if they come at the cost of slightly increased model complexity.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In conclusion, selecting **40 features** provides an optimal configuration that balances precision and recall while capturing minor but valuable performance gains. This choice is particularly beneficial for applications where maximizing positive case identification (Recall) and maintaining a balanced performance (F1 Score) are critical to model success.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with RFE Selected Features:\n",
      " AUC Score  Precision Score  Recall Score  F1 Score\n",
      "  0.761797         0.180884      0.689687  0.286601\n",
      "\n",
      "Evaluation with All Features:\n",
      " AUC Score  Precision Score  Recall Score  F1 Score\n",
      "   0.76277         0.179713      0.684554  0.284689\n",
      "\n",
      "Comparison of Model Performance:\n",
      "                       AUC Score  Precision Score  Recall Score  F1 Score\n",
      "RFE Selected Features   0.761797         0.180884      0.689687  0.286601\n",
      "All Features            0.762770         0.179713      0.684554  0.284689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_train = FE_merged_train_df.drop(columns=[\"TARGET\"])  # Replace `TARGET` with your actual target column name\n",
    "y_train = FE_merged_train_df[\"TARGET\"]\n",
    "X_val = FE_merged_val_df.drop(columns=[\"TARGET\"])\n",
    "y_val = FE_merged_val_df[\"TARGET\"]\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(class_weight=\"balanced\", max_iter=3000, random_state=42)\n",
    "\n",
    "# Set up RFE with the model \n",
    "n_features_to_select = 40 \n",
    "rfe = RFE(model, n_features_to_select=n_features_to_select)\n",
    "\n",
    "# Fit RFE on the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Extract the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_no_split(X_train, y_train, X_val, y_val):\n",
    "    # Initialize and train logistic regression model\n",
    "    model = LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    auc = roc_auc_score(y_val, y_pred_prob)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        \"AUC Score\": auc,\n",
    "        \"Precision Score\": precision,\n",
    "        \"Recall Score\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "\n",
    "# Prepare the training and validation sets for selected features\n",
    "selected_train_df = FE_merged_train_df[selected_features.tolist() + [\"TARGET\"]]\n",
    "selected_val_df = FE_merged_val_df[selected_features.tolist() + [\"TARGET\"]]\n",
    "\n",
    "# Split features and target\n",
    "X_train_selected = selected_train_df.drop(columns=[\"TARGET\"])\n",
    "y_train_selected = selected_train_df[\"TARGET\"]\n",
    "X_val_selected = selected_val_df.drop(columns=[\"TARGET\"])\n",
    "y_val_selected = selected_val_df[\"TARGET\"]\n",
    "\n",
    "# Evaluate model with selected features\n",
    "print(\"Evaluation with RFE Selected Features:\")\n",
    "selected_features_results = evaluate_model_no_split(X_train_selected, y_train_selected, X_val_selected, y_val_selected)\n",
    "print(pd.DataFrame(selected_features_results, index=[\"RFE Selected Features\"]).to_string(index=False))\n",
    "\n",
    "# Split features and target for all features\n",
    "X_train_all = FE_merged_train_df.drop(columns=[\"TARGET\"])\n",
    "y_train_all = FE_merged_train_df[\"TARGET\"]\n",
    "X_val_all = FE_merged_val_df.drop(columns=[\"TARGET\"])\n",
    "y_val_all = FE_merged_val_df[\"TARGET\"]\n",
    "\n",
    "# Evaluate model with all features\n",
    "print(\"\\nEvaluation with All Features:\")\n",
    "all_features_results = evaluate_model_no_split(X_train_all, y_train_all, X_val_all, y_val_all)\n",
    "print(pd.DataFrame(all_features_results, index=[\"All Features\"]).to_string(index=False))\n",
    "\n",
    "# Combine and display comparison\n",
    "comparison_df = pd.DataFrame([selected_features_results, all_features_results], index=[\"RFE Selected Features\", \"All Features\"])\n",
    "print(\"\\nComparison of Model Performance:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### new segment of pipeline, there will be the option to create all features, or just the rfe set\n",
    "selected_features = [\n",
    "    'EXT_SOURCE_2', 'EXT_SOURCE_3', 'AMT_ANNUITY', 'DAYS_EMPLOYED',\n",
    "    'AMT_CREDIT', 'AMT_INCOME_TOTAL', 'EXT_SOURCE_1',\n",
    "    'AMT_REQ_CREDIT_BUREAU_YEAR', 'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "    'OBS_60_CNT_SOCIAL_CIRCLE', 'NAME_EDUCATION_TYPE',\n",
    "    'NAME_FAMILY_STATUS_Married', 'CODE_GENDER', 'STABILITY_INDEX',\n",
    "    'CREDIT_BUREAU_REQ_TOTAL', 'CNT_DRAWINGS_ATM_CURRENT_sum',\n",
    "    'AMT_TOTAL_RECEIVABLE_mean', 'AMT_BALANCE_mean',\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL_mean', 'AMT_INST_MIN_REGULARITY_mean',\n",
    "    'AMT_RECIVABLE_mean', 'AMT_RECEIVABLE_PRINCIPAL_mean',\n",
    "    'AMT_RECIVABLE_sum', 'AMT_RECEIVABLE_PRINCIPAL_sum',\n",
    "    'CNT_INSTALMENT_MATURE_CUM_sum', 'AMT_INCOME_QUARTILE',\n",
    "    'AMT_INCOME_TOTAL_squared', 'INCOME_BIN_CREDIT',\n",
    "    'INCOME_QUARTILE_ANNUITY_RATIO', 'INCOME_QUARTILE_EXT_SOURCE2',\n",
    "    'INCOME_QUARTILE_EXT_SOURCE3', 'INCOME_QUARTILE_AGE',\n",
    "    'DEBT_TO_CREDIT_QUARTILE', 'binary_feature', 'income_days_birth_ratio',\n",
    "    'days_employed_days_birth_ratio', 'credit_income_ratio',\n",
    "    'annuity_credit_ratio', 'credit_utilization_ratio', 'debt_asset_ratio', \"TARGET\"\n",
    "]\n",
    "\n",
    "# Custom transformer for selecting RFE-selected features\n",
    "class RFEFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, selected_features):\n",
    "        self.selected_features = selected_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.selected_features]\n",
    "\n",
    "# Define the feature engineering pipeline with RFE feature selection\n",
    "def create_feature_engineering_pipeline_rfe(columns_to_scale, selected_features, index_column=\"SK_ID_CURR\"):\n",
    "    feature_pipeline_rfe = Pipeline([\n",
    "        ('non_linear_income_features', NonLinearIncomeFeatures()),\n",
    "        ('wealth_features', WealthFeatures()),\n",
    "        ('overextension_features', OverextensionFeatures()),\n",
    "        ('scaling', ScaleColumns(columns_to_scale=columns_to_scale)),\n",
    "        ('set_index', SetIndex(index_column=index_column)),\n",
    "        ('feature_selection', RFEFeatureSelector(selected_features=selected_features))  # RFE feature selection step\n",
    "    ])\n",
    "    return feature_pipeline_rfe\n",
    "\n",
    "###this code can be found copied to the pipelines.py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Gains from RFE Selected Features vs. All Features\n",
    "\n",
    "### Model Performance Comparisons\n",
    "\n",
    "| Evaluation Configuration  | AUC Score | Precision | Recall   | F1 Score | Gain in AUC (%) | Gain in Precision (%) | Gain in Recall (%) | Gain in F1 Score (%) |\n",
    "|---------------------------|-----------|-----------|----------|----------|-----------------|-----------------------|--------------------|-----------------------|\n",
    "| **All Features**          | 0.762770  | 0.179713  | 0.684554 | 0.284689 | -               | -                     | -                  | -                     |\n",
    "| **RFE Selected Features** | 0.761797  | 0.180884  | 0.689687 | 0.286601 | -0.13%          | +0.65%                | +0.74%             | +0.67%                |\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **AUC Score**:\n",
    "   - The AUC with RFE-selected features saw a slight decrease of -0.13% compared to using all features, indicating a minimal reduction in the model's discrimination ability.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Precision improved by +0.65% with RFE-selected features, suggesting that the model with selected features provides a marginally better rate of true positives among predicted positives.\n",
    "\n",
    "3. **Recall**:\n",
    "   - Recall increased by +0.74% with RFE-selected features, indicating a slightly higher proportion of actual positives captured when using the RFE-selected subset.\n",
    "\n",
    "4. **F1 Score**:\n",
    "   - The F1 score gained +0.67% with RFE-selected features, reflecting a modest improvement in balancing precision and recall compared to using all features.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The model with RFE-selected features demonstrated small but meaningful gains in Precision, Recall, and F1 Score over the model using all features, while incurring only a minor reduction in AUC. These results suggest that the RFE-selected feature subset achieves comparable (or slightly improved) performance with reduced complexity. By focusing on a smaller, more relevant feature set, the model may benefit from improved interpretability and reduced risk of overfitting, with minimal trade-offs in performance.\n",
    "\n",
    "\n",
    "| Metric          | RFE Selected Features | Baseline Scaled | Gain (RFE vs. Baseline Scaled) |\n",
    "|-----------------|-----------------------|-----------------|-------------------------------|\n",
    "| **AUC Score**   | 0.7618                | 0.7445          | +2.32%                        |\n",
    "| **Precision**   | 0.1809                | 0.1755          | +3.07%                        |\n",
    "| **Recall**      | 0.6897                | 0.6686          | +3.16%                        |\n",
    "| **F1 Score**    | 0.2866                | 0.2780          | +3.09%                        |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Credit Risk Kernel",
   "language": "python",
   "name": "credit_risk_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
